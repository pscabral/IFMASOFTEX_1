{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDN1RDXRD7yxsJASSKUbrO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pscabral/IFMASOFTEX_1/blob/main/Untitled190_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "# Especifique o ID do arquivo e o nome do arquivo de saída\n",
        "file_id = '1aX48j7lKyE0c66tMZEesOwNncFbyvu6X'\n",
        "output = 'dataset.zip'\n",
        "\n",
        "# Baixe o arquivo do Google Drive\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output, quiet=False)\n",
        "\n",
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "PQKhxEzq5AMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def criar_rotulos(diretorio_raiz):\n",
        "    for root, dirs, files in os.walk(diretorio_raiz):\n",
        "        for imagem_nome in files:\n",
        "            if imagem_nome.endswith(\".jpg\"):\n",
        "                imagem_path = os.path.join(root, imagem_nome)\n",
        "\n",
        "                # Lógica para obter as coordenadas da caixa delimitadora e classe\n",
        "                classe = obter_classe(imagem_nome)  # Implemente a função obter_classe conforme necessário\n",
        "                x, y, largura_rel, altura_rel = obter_coordenadas(imagem_path)  # Implemente a função obter_coordenadas conforme necessário\n",
        "\n",
        "                # Criar diretório de rótulos se não existir\n",
        "                diretorio_rotulos = os.path.join(root, \"labels\")\n",
        "                if not os.path.exists(diretorio_rotulos):\n",
        "                    os.makedirs(diretorio_rotulos)\n",
        "\n",
        "                # Salvar rótulo em um arquivo de texto\n",
        "                rotulo_path = os.path.join(diretorio_rotulos, imagem_nome.replace(\".jpg\", \".txt\"))\n",
        "                with open(rotulo_path, \"w\") as arquivo_rotulo:\n",
        "                    arquivo_rotulo.write(\"{} {} {} {} {}\\n\".format(classe, x, y, largura_rel, altura_rel))\n",
        "\n",
        "# Função de exemplo para obter a classe a partir do nome da imagem\n",
        "def obter_classe(imagem_nome):\n",
        "    # Implemente a lógica para extrair a classe do nome da imagem\n",
        "    # Este é apenas um exemplo, ajuste conforme necessário\n",
        "    if \"apple\" in imagem_nome:\n",
        "        return 0  # Classe para maçã\n",
        "    elif \"banana\" in imagem_nome:\n",
        "        return 1  # Classe para banana\n",
        "    else:\n",
        "        return 2  # Classe padrão\n",
        "\n",
        "# Função de exemplo para obter as coordenadas da caixa delimitadora\n",
        "def obter_coordenadas(imagem_path):\n",
        "    # Implemente a lógica para calcular as coordenadas da caixa delimitadora\n",
        "    # Este é apenas um exemplo, ajuste conforme necessário\n",
        "    return 0.5, 0.5, 0.4, 0.3  # Coordenadas de exemplo\n",
        "\n",
        "# Exemplo de uso\n",
        "criar_rotulos(\"/content/dataset_3/train\")\n",
        "criar_rotulos(\"/content/dataset_3/test\")\n",
        "criar_rotulos(\"/content/dataset_3/valid\")\n"
      ],
      "metadata": {
        "id": "1I8A1eIBoivu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Lista de classes\n",
        "lista_de_classes = ['chilli pepper', 'pineapple', 'cucumber', 'capsicum', 'mango', 'cauliflower', 'tomato', 'cabbage', 'bell pepper', 'pomegranate', 'apple', 'eggplant', 'lemon', 'sweetcorn', 'paprika', 'turnip', 'corn', 'grapes', 'onion', 'peas', 'raddish', 'potato', 'spinach', 'soy beans', 'kiwi', 'pear', 'carrot', 'ginger', 'watermelon', 'garlic', 'sweetpotato', 'beetroot', 'orange', 'jalepeno', 'banana', 'lettuce']\n",
        "\n",
        "def criar_rotulos(diretorio_raiz):\n",
        "    for root, dirs, files in os.walk(diretorio_raiz):\n",
        "        for imagem_nome in files:\n",
        "            if imagem_nome.endswith(\".jpg\"):\n",
        "                imagem_path = os.path.join(root, imagem_nome)\n",
        "\n",
        "                # Lógica para obter as coordenadas da caixa delimitadora e classe\n",
        "                classe = obter_classe(imagem_nome)  # Implemente a função obter_classe conforme necessário\n",
        "                x, y, largura_rel, altura_rel = obter_coordenadas(imagem_path)  # Implemente a função obter_coordenadas conforme necessário\n",
        "\n",
        "                # Criar diretório de rótulos se não existir\n",
        "                diretorio_rotulos = os.path.join(root, \"labels\")\n",
        "                if not os.path.exists(diretorio_rotulos):\n",
        "                    os.makedirs(diretorio_rotulos)\n",
        "\n",
        "                # Salvar rótulo em um arquivo de texto\n",
        "                rotulo_path = os.path.join(diretorio_rotulos, imagem_nome.replace(\".jpg\", \".txt\"))\n",
        "                with open(rotulo_path, \"w\") as arquivo_rotulo:\n",
        "                    arquivo_rotulo.write(\"{} {} {} {} {}\\n\".format(classe, x, y, largura_rel, altura_rel))\n",
        "\n",
        "                # Adicionar verificação\n",
        "                print(f\"Rótulo criado para: {imagem_path}\")\n",
        "                print(f\"Verificando se o rótulo corresponde à imagem...\")\n",
        "\n",
        "                # Verificar se o arquivo de rótulo existe\n",
        "                if os.path.exists(rotulo_path):\n",
        "                    print(f\"Arquivo de rótulo encontrado: {rotulo_path}\")\n",
        "                else:\n",
        "                    print(f\"ERRO: Arquivo de rótulo não encontrado para {imagem_path}\")\n",
        "\n",
        "# Função para obter a classe a partir do nome da imagem\n",
        "def obter_classe(imagem_nome):\n",
        "    # Ajuste a lógica para extrair a classe do nome da imagem\n",
        "    # com base na lista de classes fornecida\n",
        "    for idx, classe in enumerate(lista_de_classes):\n",
        "        if classe.lower() in imagem_nome.lower():\n",
        "            return idx\n",
        "    return -1  # Retorna -1 se a classe não for encontrada na lista\n",
        "\n",
        "# Função para obter as coordenadas da caixa delimitadora\n",
        "def obter_coordenadas(imagem_path):\n",
        "    # Implemente a lógica para calcular as coordenadas da caixa delimitadora\n",
        "    # Este é apenas um exemplo, ajuste conforme necessário\n",
        "    return 0.5, 0.5, 0.4, 0.3  # Coordenadas de exemplo\n",
        "\n",
        "# Exemplo de uso\n",
        "criar_rotulos(\"/content/dataset_3/train\")\n",
        "criar_rotulos(\"/content/dataset_3/test\")\n",
        "criar_rotulos(\"/content/dataset_3/valid\")\n"
      ],
      "metadata": {
        "id": "nFOaL5h7o96G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/dataset_3'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "lvvyvhnskaGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!curl -L \"https://universe.roboflow.com/ds/3XeB6YQNwJ?key=iTPn6nfEH0\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "id": "i_uubynUqkzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "train = os.listdir('/content/dataset_3/train')\n",
        "test = os.listdir('/content/dataset_3/test')\n",
        "val = os.listdir('/content/dataset_3/valid')"
      ],
      "metadata": {
        "id": "fpZBqlw7qbP-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train), len(test),len(val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3Tm18rhqmw_",
        "outputId": "703102c4-cc3f-4ccb-c42e-9c6b9899c4c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 36 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in train:\n",
        "    if file[-3:] == 'txt':\n",
        "        shutil.move(f'/content/dataset_3/train/{file}',f'/content/dataset_3/train/{file}')\n",
        "for file in test:\n",
        "    if file[-3:] == 'txt':\n",
        "        shutil.move(f'/content/dataset_3/test/{file}',f'/content/dataset_3/test/{file}')\n",
        "for file in val:\n",
        "    if file[-3:] == 'txt':\n",
        "        shutil.move(f'/content/dataset_3/valid/{file}',f'//content/dataset_3/valid/{file}')"
      ],
      "metadata": {
        "id": "6bzLGM9Oqtzm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/dataset_3/train')),len(os.listdir('/content/dataset_3/train')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z89KjwE4rQ0I",
        "outputId": "eb6ff073-95eb-457e-9400-befb0f521083"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install super-gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W7jIeUN2rnW0",
        "outputId": "0ab60758-4f79-4880-980c-f1849d7c029d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting super-gradients\n",
            "  Downloading super_gradients-3.4.1-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (4.66.1)\n",
            "Collecting boto3>=1.17.15 (from super-gradients)\n",
            "  Downloading boto3-1.29.1-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (4.19.2)\n",
            "Collecting Deprecated>=1.2.11 (from super-gradients)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (4.8.0.76)\n",
            "Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (3.7.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (5.9.5)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (2.14.1)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (67.7.2)\n",
            "Collecting coverage~=5.3.1 (from super-gradients)\n",
            "  Downloading coverage-5.3.1.tar.gz (684 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.5/684.5 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (0.16.0+cu118)\n",
            "Collecting sphinx~=4.0.2 (from super-gradients)\n",
            "  Downloading Sphinx-4.0.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-rtd-theme (from super-gradients)\n",
            "  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics==0.8 (from super-gradients)\n",
            "  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.2.0 (from super-gradients)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf (from super-gradients)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime==1.13.1 (from super-gradients)\n",
            "  Downloading onnxruntime-1.13.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx==1.13.0 (from super-gradients)\n",
            "  Downloading onnx-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (9.4.0)\n",
            "Requirement already satisfied: pip-tools>=6.12.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (6.13.0)\n",
            "Collecting pyparsing==2.4.5 (from super-gradients)\n",
            "  Downloading pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.3.2 (from super-gradients)\n",
            "  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Collecting pycocotools==2.0.6 (from super-gradients)\n",
            "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (3.20.3)\n",
            "Collecting treelib==1.6.1 (from super-gradients)\n",
            "  Downloading treelib-1.6.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting termcolor==1.1.0 (from super-gradients)\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (23.2)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (0.41.3)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (2.16.1)\n",
            "Collecting stringcase>=1.2.0 (from super-gradients)\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<=1.23 (from super-gradients)\n",
            "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from super-gradients)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting json-tricks==3.16.1 (from super-gradients)\n",
            "  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting onnx-simplifier<1.0,>=0.4.3 (from super-gradients)\n",
            "  Downloading onnx_simplifier-0.4.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting data-gradients>=0.3.0 (from super-gradients)\n",
            "  Downloading data_gradients-0.3.0-py3-none-any.whl (458 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.9/458.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.0->super-gradients) (4.5.0)\n",
            "Collecting coloredlogs (from onnxruntime==1.13.1->super-gradients)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->super-gradients) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->super-gradients) (1.12)\n",
            "Collecting pyDeprecate==0.3.* (from torchmetrics==0.8->super-gradients)\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from treelib==1.6.1->super-gradients) (0.18.3)\n",
            "Collecting botocore<1.33.0,>=1.32.1 (from boto3>=1.17.15->super-gradients)\n",
            "  Downloading botocore-1.32.1-py3-none-any.whl (11.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.17.15->super-gradients)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3>=1.17.15->super-gradients)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.3.0->super-gradients) (3.11.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.3.0->super-gradients) (0.12.2)\n",
            "Collecting xhtml2pdf==0.2.11 (from data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading xhtml2pdf-0.2.11.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.3.0->super-gradients) (3.1.2)\n",
            "Collecting imagededup (from data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading imagededup-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting arabic-reshaper>=3.0.0 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: html5lib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (1.1)\n",
            "Collecting pyHanko>=0.12.1 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading pyHanko-0.20.1-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading pyhanko_certvalidator-0.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf>=3.1.0 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading pypdf-3.17.1-py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.6/277.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-bidi>=0.4.2 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Collecting reportlab<4,>=3.5.53 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading reportlab-3.6.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting svglib>=1.2.1 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading svglib-1.5.1.tar.gz (913 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.9/913.9 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated>=1.2.11->super-gradients) (1.14.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.2.0->super-gradients)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (0.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (1.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->super-gradients) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier<1.0,>=0.4.3->super-gradients) (13.6.0)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients) (1.0.3)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients) (8.1.7)\n",
            "Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients) (23.1.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.6)\n",
            "Collecting docutils<0.18,>=0.14 (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.31.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (3.5.1)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients) (3.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients) (2.1.0)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->super-gradients)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.33.0,>=1.32.1->boto3>=1.17.15->super-gradients) (2.0.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->super-gradients) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->data-gradients>=0.3.0->super-gradients) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (2023.7.22)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.12.1->super-gradients) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.12.1->super-gradients) (2.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.13.1->super-gradients)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients>=0.3.0->super-gradients) (1.2.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients>=0.3.0->super-gradients) (1.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier<1.0,>=0.4.3->super-gradients) (3.0.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn->data-gradients>=0.3.0->super-gradients) (1.5.3)\n",
            "INFO: pip is looking at multiple versions of sphinxcontrib-applehelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-applehelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading sphinxcontrib_applehelp-1.0.6-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_applehelp-1.0.5-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.6/120.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-devhelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-devhelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading sphinxcontrib_devhelp-1.0.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_devhelp-1.0.3-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-htmlhelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-htmlhelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-qthelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-qthelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading sphinxcontrib_qthelp-1.0.5-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_qthelp-1.0.4-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-serializinghtml to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-serializinghtml (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.13.1->super-gradients) (1.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.0.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (0.5.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier<1.0,>=0.4.3->super-gradients) (0.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn->data-gradients>=0.3.0->super-gradients) (2023.3.post1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (0.5.0)\n",
            "Collecting asn1crypto>=1.5.1 (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qrcode>=6.1 (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tzlocal>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (5.2)\n",
            "Collecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading pyhanko_certvalidator-0.24.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (41.0.5)\n",
            "Collecting oscrypto>=1.1.0 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uritools>=3.0.1 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading uritools-4.0.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->super-gradients) (3.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (4.9.3)\n",
            "Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (1.2.1)\n",
            "Collecting cssselect2>=0.2.0 (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients>=0.3.0->super-gradients) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients>=0.3.0->super-gradients) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (1.16.0)\n",
            "Collecting pypng (from qrcode>=6.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients)\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.3.0->super-gradients) (2.21)\n",
            "Building wheels for collected packages: pycocotools, termcolor, treelib, coverage, xhtml2pdf, antlr4-python3-runtime, stringcase, svglib\n",
            "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=377132 sha256=0735809b3999c500b630d2f6b629fb513115e644fa6210770fdc9df664a3f987\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=7055925363c8a5a1349250fb316fb2396e7052bc229cc5a252ff025b8ac66986\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treelib: filename=treelib-1.6.1-py3-none-any.whl size=18370 sha256=469a4e85f76b1d9989d4a1bf8904d1133e0a04dd264c18e4111009c66173f5ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/72/8b/76569b82bf280a03c4e294c3b29ee2398217186369c427ed4b\n",
            "  Building wheel for coverage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for coverage: filename=coverage-5.3.1-cp310-cp310-linux_x86_64.whl size=235254 sha256=d4bf52168b7be35d7f9fcd9c1229a7fb427dd4d159bfb15c8f1933d8c0710978\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/70/10/313be697f460d6024cfa94b7f0e22ffc1c53aab718fb4f42af\n",
            "  Building wheel for xhtml2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xhtml2pdf: filename=xhtml2pdf-0.2.11-py3-none-any.whl size=262645 sha256=5191b684364fb96fe7f875f2cf3383119ca1ee8d2f1401ce73ee2fde5207f9a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/77/fb/e473c11c4e30a7680bf5b1b7f1d07ef04932184a2f39118e8d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=4b62b3ecf9225e756962f107625c0f35bc3fb92dd4b182d8e48b389a879f4dbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3569 sha256=13feb83eb837b6c91683994016d3f0633e4e7c948f584308df7a10b3a54dc428\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/ba/22/1a2d952a9ce8aa86e42fda41e2c87fdaf20e238c88bf8df013\n",
            "  Building wheel for svglib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for svglib: filename=svglib-1.5.1-py3-none-any.whl size=30901 sha256=2198c63d1f7f76b36b1ac1e2ac40db686c845929eb7717dff9b05925d954eef8\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/9f/90/f37f4b9dbf82987a24ae14f15586e96715cb669a4710b3b85d\n",
            "Successfully built pycocotools termcolor treelib coverage xhtml2pdf antlr4-python3-runtime stringcase svglib\n",
            "Installing collected packages: termcolor, stringcase, pypng, json-tricks, einops, asn1crypto, arabic-reshaper, antlr4-python3-runtime, uritools, treelib, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, reportlab, rapidfuzz, qrcode, python-bidi, pypdf, pyparsing, pyDeprecate, oscrypto, omegaconf, numpy, jmespath, humanfriendly, docutils, Deprecated, coverage, sphinx, onnx, hydra-core, cssselect2, coloredlogs, botocore, torchmetrics, svglib, sphinxcontrib-jquery, s3transfer, pyhanko-certvalidator, onnxruntime, onnx-simplifier, sphinx-rtd-theme, pyHanko, pycocotools, imagededup, boto3, xhtml2pdf, data-gradients, super-gradients\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.3.0\n",
            "    Uninstalling termcolor-2.3.0:\n",
            "      Successfully uninstalled termcolor-2.3.0\n",
            "  Attempting uninstall: sphinxcontrib-serializinghtml\n",
            "    Found existing installation: sphinxcontrib-serializinghtml 1.1.9\n",
            "    Uninstalling sphinxcontrib-serializinghtml-1.1.9:\n",
            "      Successfully uninstalled sphinxcontrib-serializinghtml-1.1.9\n",
            "  Attempting uninstall: sphinxcontrib-qthelp\n",
            "    Found existing installation: sphinxcontrib-qthelp 1.0.6\n",
            "    Uninstalling sphinxcontrib-qthelp-1.0.6:\n",
            "      Successfully uninstalled sphinxcontrib-qthelp-1.0.6\n",
            "  Attempting uninstall: sphinxcontrib-htmlhelp\n",
            "    Found existing installation: sphinxcontrib-htmlhelp 2.0.4\n",
            "    Uninstalling sphinxcontrib-htmlhelp-2.0.4:\n",
            "      Successfully uninstalled sphinxcontrib-htmlhelp-2.0.4\n",
            "  Attempting uninstall: sphinxcontrib-devhelp\n",
            "    Found existing installation: sphinxcontrib-devhelp 1.0.5\n",
            "    Uninstalling sphinxcontrib-devhelp-1.0.5:\n",
            "      Successfully uninstalled sphinxcontrib-devhelp-1.0.5\n",
            "  Attempting uninstall: sphinxcontrib-applehelp\n",
            "    Found existing installation: sphinxcontrib-applehelp 1.0.7\n",
            "    Uninstalling sphinxcontrib-applehelp-1.0.7:\n",
            "      Successfully uninstalled sphinxcontrib-applehelp-1.0.7\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 5.0.2\n",
            "    Uninstalling Sphinx-5.0.2:\n",
            "      Successfully uninstalled Sphinx-5.0.2\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.7\n",
            "    Uninstalling pycocotools-2.0.7:\n",
            "      Successfully uninstalled pycocotools-2.0.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 antlr4-python3-runtime-4.9.3 arabic-reshaper-3.0.0 asn1crypto-1.5.1 boto3-1.29.1 botocore-1.32.1 coloredlogs-15.0.1 coverage-5.3.1 cssselect2-0.7.0 data-gradients-0.3.0 docutils-0.17.1 einops-0.3.2 humanfriendly-10.0 hydra-core-1.3.2 imagededup-0.3.2 jmespath-1.0.1 json-tricks-3.16.1 numpy-1.23.0 omegaconf-2.3.0 onnx-1.13.0 onnx-simplifier-0.4.35 onnxruntime-1.13.1 oscrypto-1.3.0 pyDeprecate-0.3.2 pyHanko-0.20.1 pycocotools-2.0.6 pyhanko-certvalidator-0.24.1 pyparsing-2.4.5 pypdf-3.17.1 pypng-0.20220715.0 python-bidi-0.4.2 qrcode-7.4.2 rapidfuzz-3.5.2 reportlab-3.6.13 s3transfer-0.7.0 sphinx-4.0.3 sphinx-rtd-theme-1.3.0 sphinxcontrib-applehelp-1.0.4 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.1 sphinxcontrib-jquery-4.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 stringcase-1.2.0 super-gradients-3.4.1 svglib-1.5.1 termcolor-1.1.0 torchmetrics-0.8.0 treelib-1.6.1 uritools-4.0.2 xhtml2pdf-0.2.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pydevd_plugins",
                  "pyparsing",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-JjEgDcrowO",
        "outputId": "ae84ffae-3e70-4f18-cc77-4f42d3fb6e4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import Trainer\n",
        "\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "trainer = Trainer(experiment_name='my_first_yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTxDvAPLr9Y8",
        "outputId": "d8debbb3-af0f-4396-a88c-21345ea0332b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The console stream is logged into /root/sg_logs/console.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-11-16 19:51:43] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n",
            "[2023-11-16 19:51:43] WARNING - __init__.py - Failed to import pytorch_quantization\n",
            "[2023-11-16 19:51:54] WARNING - calibrator.py - Failed to import pytorch_quantization\n",
            "[2023-11-16 19:51:54] WARNING - export.py - Failed to import pytorch_quantization\n",
            "[2023-11-16 19:51:54] WARNING - selective_quantization_utils.py - Failed to import pytorch_quantization\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: boto3 required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: deprecated required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: coverage required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: sphinx-rtd-theme required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: torchmetrics required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: hydra-core required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: omegaconf required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnxruntime required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnx required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: einops required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: treelib required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: stringcase required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: rapidfuzz required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: json-tricks required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: onnx-simplifier required but not found\u001b[0m\n",
            "[2023-11-16 19:51:54] WARNING - env_sanity_check.py - \u001b[31mFailed to verify installed packages: data-gradients required but not found\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import dataloaders\n",
        "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val"
      ],
      "metadata": {
        "id": "08LIyPNHr-Re"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_params = {\n",
        "    'data_dir':'/content/dataset_3/test/',\n",
        "    'train_dir':'train',\n",
        "    'train_dir':'train',\n",
        "    'val_dir':'valid',\n",
        "    'val_dir':'valid',\n",
        "    'test_dir':'test',\n",
        "    'test_dir':'/test',\n",
        "    'classes': ['chilli pepper', 'pineapple', 'cucumber', 'capsicum', 'mango', 'cauliflower', 'tomato', 'cabbage', 'bell pepper', 'pomegranate', 'apple', 'eggplant', 'lemon', 'sweetcorn', 'paprika', 'turnip', 'corn', 'grapes', 'onion', 'peas', 'raddish', 'potato', 'spinach', 'soy beans', 'kiwi', 'pear', 'carrot', 'ginger', 'watermelon', 'garlic', 'sweetpotato', 'beetroot', 'orange', 'jalepeno', 'banana', 'lettuce']\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "dY9PiA3er-WH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_params = {\n",
        "    'data_dir': '/content/dataset_3/test/',\n",
        "    'train_dir': 'train',\n",
        "    'val_dir': 'valid',\n",
        "    'test_dir': '/test',\n",
        "    'classes': ['chilli pepper', 'pineapple', 'cucumber', 'capsicum', 'mango', 'cauliflower', 'tomato', 'cabbage', 'bell pepper', 'pomegranate', 'apple', 'eggplant', 'lemon', 'sweetcorn', 'paprika', 'turnip', 'corn', 'grapes', 'onion', 'peas', 'raddish', 'potato', 'spinach', 'soy beans', 'kiwi', 'pear', 'carrot', 'ginger', 'watermelon', 'garlic', 'sweetpotato', 'beetroot', 'orange', 'jalepeno', 'banana', 'lettuce']\n",
        "}\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "train_data = coco_detection_yolo_format_train(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'dir': dataset_params['train_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size': 16,\n",
        "        'num_workers': 2\n",
        "    }\n",
        ")\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['val_dir'],  # Assuming 'val_dir' contains both images and labels\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size': 16,\n",
        "        'num_workers': 2\n",
        "    }\n",
        ")\n",
        "\n",
        "test_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['test_dir'],  # Assuming 'test_dir' contains both images and labels\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size': 16,\n",
        "        'num_workers': 2\n",
        "    }\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Gy4aB_sms7tL",
        "outputId": "b763bcf4-fef5-4914-d6d5-f1e38f1fe091"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-2f230d4f0774>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m train_data = coco_detection_yolo_format_train(\n\u001b[0m\u001b[1;32m     12\u001b[0m     dataset_params={\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/dataloaders/dataloaders.py\u001b[0m in \u001b[0;36mcoco_detection_yolo_format_train\u001b[0;34m(dataset_params, dataloader_params)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mregister_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOCO_DETECTION_YOLO_FORMAT_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcoco_detection_yolo_format_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_params\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     return get_data_loader(\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coco_detection_yolo_format_base_dataset_params\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mdataset_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mYoloDarknetFormatDetectionDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/dataloaders/dataloaders.py\u001b[0m in \u001b[0;36mget_data_loader\u001b[0;34m(config_name, dataset_cls, train, dataset_params, dataloader_params)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mlocal_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_local_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwait_for_the_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdataset_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset_params\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/detection_datasets/yolo_format_detection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, images_dir, labels_dir, classes, class_ids_to_ignore, ignore_invalid_labels, show_all_warnings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_fields\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_target_format\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXYXY_LABEL\u001b[0m  \u001b[0;31m# We convert yolo format (LABEL_CXCYWH) to Coco format (XYXY_LABEL) when loading the annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_all_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_all_warnings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/common/decorators/factory_decorator.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assign_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DetectionDataset.__init__() got an unexpected keyword argument 'dir'"
          ]
        }
      ]
    }
  ]
}